{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential ,Model\n",
    "from keras.layers import Dense,Dropout,Input\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    (xtrain,ytrain),(xtest,ytest) = fashion_mnist.load_data()\n",
    "    xtrain = (xtrain.astype(np.float32)-127.5/127.5)\n",
    "    xtrain = xtrain.reshape(60000,784)\n",
    "    return xtrain,ytrain,xtest,ytest\n",
    "xtrain,ytrain,xtest,ytest = load_data()\n",
    "print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_optimizer():\n",
    "    return Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 784)               803600    \n",
      "=================================================================\n",
      "Total params: 1,486,352\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_generator():\n",
    "    generator = Sequential()\n",
    "    generator.add(Dense(256,input_dim = 100))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(512))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(1024))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(784,activation='tanh'))\n",
    "    generator.compile(loss='binary_crossentropy',optimizer=adam_optimizer(),metrics=['accuracy'])\n",
    "    \n",
    "    generator.summary()\n",
    "    return generator\n",
    "\n",
    "g = create_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,460,225\n",
      "Trainable params: 1,460,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_discriminator():\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(1024,input_dim=784))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    discriminator.add(Dense(512))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    discriminator.add(Dense(256))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "                      \n",
    "    discriminator.add(Dense(1,activation='sigmoid'))\n",
    "    discriminator.compile(loss='binary_crossentropy',optimizer=adam_optimizer(),metrics=['accuracy'])\n",
    "    return discriminator\n",
    "d = create_discriminator()\n",
    "d.summary()                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sequential_8 (Sequential)    (None, 784)               1486352   \n",
      "_________________________________________________________________\n",
      "sequential_9 (Sequential)    (None, 1)                 1460225   \n",
      "=================================================================\n",
      "Total params: 2,946,577\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 1,460,225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_gan(discriminator,generator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(inputs = gan_input,outputs = gan_output)\n",
    "    gan.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "    return gan\n",
    "gan = create_gan(d,g)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genrated_images(epoch,generator,examples=100,dim=(10,10),figsize=(10,10)):\n",
    "    noise = np.random.normal(loc=0,scale=1,size=[examples,100])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(100,28,28)\n",
    "    plt.figure(figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 784)               803600    \n",
      "=================================================================\n",
      "Total params: 1,486,352\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "epoch 1\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:15<00:00,  8.02it/s]\n",
      "  1%|          | 1/128 [00:00<00:13,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:14<00:00,  8.83it/s]\n",
      "  1%|          | 1/128 [00:00<00:18,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:13<00:00,  9.17it/s]\n",
      "  1%|          | 1/128 [00:00<00:14,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:14<00:00,  8.87it/s]\n",
      "  1%|          | 1/128 [00:00<00:14,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:14<00:00,  8.99it/s]\n",
      "  1%|          | 1/128 [00:00<00:14,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:14<00:00,  8.86it/s]\n",
      "  1%|          | 1/128 [00:00<00:12,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:13<00:00,  9.22it/s]\n",
      "  1%|          | 1/128 [00:00<00:14,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:13<00:00,  9.32it/s]\n",
      "  2%|▏         | 2/128 [00:00<00:12,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:14<00:00,  8.95it/s]\n",
      "  1%|          | 1/128 [00:00<00:16,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:15<00:00,  8.37it/s]\n",
      "  1%|          | 1/128 [00:00<00:15,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:15<00:00,  8.40it/s]\n",
      "  1%|          | 1/128 [00:00<00:15,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:15<00:00,  8.49it/s]\n",
      "  1%|          | 1/128 [00:00<00:14,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:14<00:00,  8.72it/s]\n",
      "  1%|          | 1/128 [00:00<00:16,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:16<00:00,  8.00it/s]\n",
      "  1%|          | 1/128 [00:00<00:14,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6/128 [00:00<00:15,  8.02it/s]"
     ]
    }
   ],
   "source": [
    "def training(epochs=1,batch_size=128):\n",
    "    (xtrain,ytrain,xtest,ytest) = load_data()\n",
    "    batch_count = xtrain.shape[0]/batch_size\n",
    "    \n",
    "    generator = create_generator()\n",
    "    discriminator = create_discriminator()\n",
    "    gan = create_gan(discriminator,generator)\n",
    "    \n",
    "    for e in range(1,epochs+1):\n",
    "        print(\"epoch %d\"%e)\n",
    "        for _ in tqdm(range(batch_size)):\n",
    "            noise = np.random.normal(0,1,[batch_size,100])\n",
    "            generated_images = generator.predict(noise)\n",
    "            image_batch = xtrain[np.random.randint(low=0,high=xtrain.shape[0],size=batch_size)]\n",
    "            x = np.concatenate([image_batch,generated_images])\n",
    "            \n",
    "            y_dis = np.zeros(2*batch_size)\n",
    "            y_dis[:batch_size] = 0.9\n",
    "            \n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(x,y_dis)\n",
    "            \n",
    "            noise = np.random.normal(0,1,[batch_size,100])\n",
    "            y_gen = np.ones(batch_size)\n",
    "          \n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise,y_gen)\n",
    "            \n",
    "        if e%100==0:\n",
    "            plot_generated_images(e,generator)\n",
    "training(200,128)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
